#!/usr/bin/env python3
"""
Vertex AIã‚’ä½¿ã£ãŸãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ã€AIæ„Ÿæ¤œå‡ºç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹
"""

import json
from pathlib import Path
from typing import List, Dict
from google.cloud import aiplatform

# Google Cloudè¨­å®š
PROJECT_ID = "your-project-id"
LOCATION = "us-central1"
DATASET_PATH = Path(__file__).parent.parent / "data" / "collected_texts.json"


def load_training_data() -> List[Dict]:
    """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    with open(DATASET_PATH, "r", encoding="utf-8") as f:
        return json.load(f)


def prepare_training_examples(data: List[Dict]) -> List[Dict]:
    """
    Vertex AIå½¢å¼ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
    
    JSONLå½¢å¼:
    {"input_text": "...", "output_text": "..."}
    """
    examples = []
    
    for item in data:
        text = item["text"]
        label = item["label"]
        
        # ãƒ©ãƒ™ãƒ«ã«å¿œã˜ã¦å‡ºåŠ›ã‚’ç”Ÿæˆ
        if label == "ai_bad":
            output = json.dumps({
                "has_ai_feel": True,
                "assessment": "ã“ã®æ–‡ç« ã«ã¯AIæ„ŸãŒã‚ã‚Šã¾ã™"
            }, ensure_ascii=False)
        elif label == "good":
            output = json.dumps({
                "has_ai_feel": False,
                "assessment": "è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ–‡ç« ã§ã™"
            }, ensure_ascii=False)
        else:
            continue
        
        examples.append({
            "input_text": f"ä»¥ä¸‹ã®æ–‡ç« ã‚’åˆ†æã—ã¦ãã ã•ã„:\n{text}",
            "output_text": output
        })
    
    return examples


def save_training_data(examples: List[Dict], output_path: str = "data/training.jsonl"):
    """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’JSONLå½¢å¼ã§ä¿å­˜"""
    with open(output_path, "w", encoding="utf-8") as f:
        for example in examples:
            f.write(json.dumps(example, ensure_ascii=False) + "\n")
    
    print(f"âœ… Saved {len(examples)} training examples to {output_path}")


def create_tuning_job(training_data_uri: str):
    """
    Vertex AIã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã‚’ä½œæˆ
    
    æ³¨æ„: ã“ã‚Œã¯ç°¡ç•¥åŒ–ã—ãŸä¾‹ã§ã™ã€‚å®Ÿéš›ã®ã‚³ãƒ¼ãƒ‰ã¯ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚„
    APIãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«åˆã‚ã›ã¦èª¿æ•´ãŒå¿…è¦ã§ã™ã€‚
    """
    aiplatform.init(project=PROJECT_ID, location=LOCATION)
    
    # ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã®è¨­å®šä¾‹
    # å®Ÿéš›ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ« (Gemini ãªã©) ã«ä¾å­˜
    tuning_job = aiplatform.PipelineJob(
        display_name="ai-feel-detector-tuning",
        template_path="gs://your-bucket/tuning_pipeline.json",
        parameter_values={
            "training_data_uri": training_data_uri,
            "base_model": "gemini-1.5-flash",
            "tuned_model_display_name": "ai-feel-detector-v1"
        }
    )
    
    tuning_job.run(sync=True)
    print(f"âœ… Tuning job completed: {tuning_job.resource_name}")


def main():
    print("ğŸ“Š Loading training data...")
    data = load_training_data()
    
    print(f"ğŸ“ Preparing {len(data)} examples...")
    examples = prepare_training_examples(data)
    
    print(f"ğŸ’¾ Saving training data...")
    save_training_data(examples)
    
    print("\n" + "="*60)
    print("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("1. data/training.jsonl ã‚’ Google Cloud Storage ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    print("2. Vertex AI Console ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã‚’ä½œæˆ")
    print("3. ã¾ãŸã¯ create_tuning_job() ã‚’å®Ÿè£…ã—ã¦è‡ªå‹•åŒ–")
    print("="*60)


if __name__ == "__main__":
    main()